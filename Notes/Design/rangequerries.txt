A very big design decision is how to efficiently implement directories.
We have two general approaches:

	there are real directory objects, which must be searched
	to map a name to an I-node number (and can be made more
	efficient by partitioning).  This is kind of slow for
	lookup, but very fast for listing.

	making names part of the keys and using ranged queries
	to do find the desired entry.  This is likely to be faster
	for lookup, but slower for listing.

Thoughts-in-progress on using ranged queries.

Many (most) KVSs implement range queries. 
Leveldb has them and they're pretty fast. 
What would a directory implementation that took advantage of them look like?

Directory inode key is still just ("%d", inode), but instead of 
partitions, directory entries are either ("%d.%s", dir_inode, name), 
or "%d.%d", dir_inode, hash(name).  If they key has the filename, then the 
contents are just the inode number and file type. 
If the key is a hash, then the value must include the name (or names - hash collisions).

Readdir offset handling:

	If the key is the name, we need to have some way to map strings 
	onto 64bit offsets. 
		First 8 characters of the name? 
		This breaks if there are several names with same first 8 chars.

	If the key is based on a hash, then the offset can be the hash, 
	but we still suffer if too many names hash to the same bucket. 

	If the offset is high-order N bits of the hash plus a 
	position-within-bucket, I think that's probably enough 
	(odds of more than N collisions in same bucket are arbitrarily small).

	Hmm.. also, maybe there's a sequence number or offset stored in the value?

	Another approach to offset is to cache the mapping from offset that we 
	return to FUSE to a key. This works as long as we don't need have 
	readdirs continue across reboots/remounts.

[TODO: storing inode in dir ent? links, lookups without path, ...? ]

Tiering & Eviction

	Do we want to be able to evict directories? using key-per-entry 
	may make this slower since we'd need to delete individual entries (not undoable though).

Timings

    Here's some timings extracted from runs of db_bench, a benchmark that comes with leveldb:

	12 byte values (an inode number and a file type+mode):
	(uncompacted):
	+readrandom   :       1.598 micros/op; (100000 of 100000 found)
	+readseq      :       0.533 micros/op;   50.1 MB/s
	Compacted:
	+readrandom   :       1.566 micros/op; (100000 of 100000 found)
	+readseq      :       0.155 micros/op;  172.6 MB/s

	4096 byte values (current directory format):
	+readrandom   :      11.873 micros/op; (100000 of 100000 found)
	+readseq      :       3.600 micros/op; 1089.2 MB/s
	Compacted:
	+readrandom   :       4.107 micros/op; (100000 of 100000 found)
	+readseq      :       2.132 micros/op; 1839.8 MB/s

	I think this means that a single lookup can be done at 3-8 times 
	faster if each directory entry is a separate key.

	On the other hand, readdir would still be faster with the old version, 
	since a single 4k random read yields 100+ directory entries.
